# install the hadoop packages
- name: Fetch HDP repo
  shell: "wget -nv http://public-repo-1.hortonworks.com/HDP/centos6/2.x/updates/2.0.6.0/hdp.repo -O /etc/yum.repos.d/hdp.repo creates=/etc/yum.repos.d/hdp.repo"
  #shell: "wget http://public-repo-1.hortonworks.com/HDP-2.0.0.2/repos/centos6/hdp.repo -O /etc/yum.repos.d/hdp.repo creates=/etc/yum.repos.d/hdp.repo"
  sudo: yes

- name: yum install hadoop
  yum: name='hadoop' state=installed
  sudo: yes

- name: yum install hadoop-hdfs
  yum: name='hadoop-hdfs' state=installed
  sudo: yes

- name: yum install hadoop-libhdfs
  yum: name='hadoop-libhdfs' state=installed
  sudo: yes

- name: yum install hadoop-yarn
  yum: name='hadoop-yarn' state=installed
  sudo: yes

- name: yum install hadoop-mapreduce
  yum: name='hadoop-mapreduce' state=installed
  sudo: yes

- name: yum install hadoop-client
  yum: name='hadoop-client' state=installed
  sudo: yes

- name: yum install openssl
  yum: name='openssl' state=installed
  sudo: yes

# install snappy compression
- name: yum install snappy
  yum: name='snappy' state=installed
  sudo: yes

- name: yum install snappy-devel
  yum: name='snappy-devel' state=installed
  sudo: yes

# install lzo compression
- name: yum install lzo
  yum: name='lzo' state=installed
  sudo: yes

- name: yum install lzo-devel
  yum: name='lzo-devel' state=installed
  sudo: yes

- name: yum install hadoop-lzo
  yum: name='hadoop-lzo' state=installed
  sudo: yes

- name: yum install hadoop-lzo-native
  yum: name='hadoop-lzo-native' state=installed
  sudo: yes


# setup shell environment variables
- shell: "grep DFS_NAME_DIR /etc/environment"
  register: directories_env_result
  ignore_errors: true

- shell: "grep HDFS_USER /etc/environment"
  register: users_and_groups_env_result
  ignore_errors: true

- shell: "grep JAVA_HOME /etc/environment"
  register: JAVA_HOME_result
  ignore_errors: true

- name: add JAVA_HOME into /etc/environment
  shell: "echo JAVA_HOME=/usr/java/default >> /etc/environment"
  when: not JAVA_HOME_result.stdout
  sudo: yes

- name: add user env variables into /etc/environment
  shell:  "grep = {{ users_and_groups_env }} | cut -d';' -f1 >> /etc/environment;"
  when: not users_and_groups_env_result.stdout
  sudo: yes

- name: add directory env variables into /etc/environment
  shell: "grep = {{ directories_env }} | cut -d';' -f1 >> /etc/environment;"
  when: not directories_env_result.stdout
  sudo: yes

# create directories
- script: create_hortonworks_dir.sh
  sudo: yes

#- shell: sh /vagrant/provisioning/roles/hdp-hadoop/files/done_copying_over_conf.sh
- name: Do we need to copy over conf files
  script: done_copying_over_conf.sh
  register: done_copying_over_conf
  ignore_errors: true

- debug: var=done_copying_over_conf

- name: copy configuration file templates to
  shell: "cp -r /vagrant/files/hortonworks_conf ~/ creates=~/hortonworks_conf"
  when: done_copying_over_conf.rc == 0

## fill in the environment variables into the config files
- name: generate config files
  script: setup_hortonworks_conf.py --namenode=localhost --secondarynamenode=localhost --rmnode=localhost --jobhistory=localhost --conf_template_dir=/home/vagrant/hortonworks_conf/ --users_and_groups_env=/vagrant/files/hortonworks_env/usersAndGroups.sh  --directories_env=/vagrant/files/hortonworks_env/directories.sh
  when: done_copying_over_conf.rc == 0

## copy the config files to the appropriate location
- script: copy_hdp_conf.sh
  when: done_copying_over_conf.rc == 0
  sudo: yes

## format the namenode
- name: is the namenode already formatted?
  script: is_namenode_formatted.sh
  register: is_namenode_formatted
  ignore_errors: true

- debug: var=is_namenode_formatted

- name: format namenode
  script: format_namenode.sh
  when: is_namenode_formatted.rc == 0
